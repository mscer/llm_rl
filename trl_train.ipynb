{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c0d60bc-8cd6-4868-80da-470491e5e2df",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57b80012-a0e2-4a7e-9756-47054fa82e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForCausalLM\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b32dd19b-815b-4f6a-bf23-0af00e262558",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/countdown_tasks/'\n",
    "dataset = load_dataset(data_path,split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "453f4b5e-735c-4fba-9e81-6103f6eef2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(seed=42).select(range(50000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0be0b387-01ee-4c18-92ab-a5193463b6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './models/Qwen/Qwen2.5-1.5B-Instruct/'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04861832-8921-4a48-83b7-8ee01098f655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_r1_prompt(numbers, target):\n",
    "    r1_prefix = [{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant. You first thinks about the reasoning process in the mind and then provides the user with the answer.\"\n",
    "      },\n",
    "      { \n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Using the numbers {numbers}, create an equation that equals {target}. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final equation and answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 = 1 </answer>.\"\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Let me solve this step by step.\\n<think>\"\n",
    "      }]\n",
    "    return {\"prompt\": tokenizer.apply_chat_template(r1_prefix, tokenize=False, continue_final_message=True), \"target\": target}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c8d083b-08fd-4c0b-a3c2-d25ffae9d2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda x: generate_r1_prompt(x[\"nums\"], x[\"target\"]))\n",
    "train_test_split = dataset.train_test_split(test_size=0.1)\n",
    " \n",
    "train_dataset = train_test_split[\"train\"]\n",
    "test_dataset = train_test_split[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae7ed19-87b6-4da3-88d3-56291b77eb64",
   "metadata": {},
   "source": [
    "# reward feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad317ad4-1113-46bb-b18b-1bd6cc830366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b5b7b70-73b2-46f0-a5e0-1bde73e4fbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_reward_func(completions, target, **kwargs):\n",
    "    \"\"\"\n",
    "    Format: <think>...</think><answer>...</answer>\n",
    "    Args:\n",
    "        completions (list[str]): Generated outputs\n",
    "        target (list[str]): Expected answers\n",
    "      \n",
    "      Returns:\n",
    "          list[float]: Reward scores\n",
    "    \"\"\"\n",
    "    rewards = []\n",
    " \n",
    "    for completion, gt in zip(completions, target):\n",
    " \n",
    "      try:\n",
    "        # add synthetic <think> as its already part of the prompt and prefilled for the assistant to more easily match the regex\n",
    "        completion = \"<think>\" + completion        \n",
    "        # Check if the format is correct\n",
    "        regex = r\"^<think>([^<]*(?:<(?!/?think>)[^<]*)*)<\\/think>\\n<answer>([\\s\\S]*?)<\\/answer>$\"\n",
    " \n",
    "        match = re.search(regex, completion, re.DOTALL) \n",
    "        # if the format is not correct, reward is 0\n",
    "        if match is None or len(match.groups()) != 2:\n",
    "            rewards.append(0.0)\n",
    "        else:\n",
    "            rewards.append(1.0)\n",
    "      except Exception:\n",
    "        rewards.append(0.0)\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f8ad495-ebae-46b5-8a22-df62f7e0800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equation_reward_func(completions, target, nums, **kwargs):\n",
    "    \"\"\"\n",
    "    Evaluates completions based on:\n",
    "    2. Mathematical correctness of the answer\n",
    " \n",
    "    Args:\n",
    "        completions (list[str]): Generated outputs\n",
    "        target (list[str]): Expected answers\n",
    "        nums (list[str]): Available numbers\n",
    "    \n",
    "    Returns:\n",
    "        list[float]: Reward scores\n",
    "    \"\"\"\n",
    "    rewards = []\n",
    "    for completion, gt, numbers in zip(completions, target, nums):\n",
    "      try:\n",
    "        # add synthetic <think> as its already part of the prompt and prefilled for the assistant to more easily match the regex\n",
    "        completion = \"<think>\" + completion\n",
    "        # Check if the format is correct\n",
    "        match = re.search(r\"<answer>(.*?)<\\/answer>\", completion)\n",
    "        if match is None:\n",
    "            rewards.append(0.0)\n",
    "            continue\n",
    "        # Extract the \"answer\" part from the completion\n",
    "        equation = match.group(1).strip()\n",
    "        # Extract all numbers from the equation\n",
    "        used_numbers = [int(n) for n in re.findall(r'\\d+', equation)]\n",
    "        \n",
    "        # Check if all numbers are used exactly once\n",
    "        if sorted(used_numbers) != sorted(numbers):\n",
    "            rewards.append(0.0)\n",
    "            continue\n",
    "        # Define a regex pattern that only allows numbers, operators, parentheses, and whitespace\n",
    "        allowed_pattern = r'^[\\d+\\-*/().\\s]+$'\n",
    "        if not re.match(allowed_pattern, equation):\n",
    "           rewards.append(0.0)\n",
    "           continue\n",
    "        \n",
    "        # Evaluate the equation with restricted globals and locals\n",
    "        result = eval(equation, {\"__builtins__\": None}, {})\n",
    "        # Check if the equation is correct and matches the ground truth\n",
    "        if abs(float(result) - float(gt)) < 1e-5:\n",
    "            rewards.append(1.0)\n",
    "        else:\n",
    "            rewards.append(0.0)\n",
    "      except Exception:\n",
    "            # If evaluation fails, reward is 0\n",
    "            rewards.append(0.0) \n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01936799-e7c2-41e0-813d-ea00b99b8223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f8fd85-6a72-4b1d-9ca2-d6e7320d68f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acf1ee3-e966-4e94-8562-8cea1104a5f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891fde88-b0f4-4ca7-8674-6ae45f42263c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8648d7f4-586d-460e-9254-5b95386b935a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-09 14:39:51,304] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mscer/workingspace/anaconda3/envs/handson_llm/bin/../lib/gcc/x86_64-conda-linux-gnu/11.2.0/../../../../x86_64-conda-linux-gnu/bin/ld: cannot find -laio: 没有那个文件或目录\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/mscer/workingspace/anaconda3/envs/handson_llm/bin/../lib/gcc/x86_64-conda-linux-gnu/11.2.0/../../../../x86_64-conda-linux-gnu/bin/ld: cannot find -lcufile: 没有那个文件或目录\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-09 14:39:52 __init__.py:183] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "from trl import GRPOConfig, GRPOTrainer, get_peft_config, ModelConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b14b8d-9929-442b-b19c-c41e7803acc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ModelConfig?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc20067e-04db-4e9e-8a22-dd617710a096",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = ModelConfig(\n",
    "    model_name_or_path=model_path,\n",
    "    torch_dtype=\"float16\",\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    use_peft=True,\n",
    "    load_in_4bit=True,\n",
    "    #lora_r = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f5fec01-d8f2-41f6-a0b2-575218d6df07",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = GRPOConfig(\n",
    "    output_dir=\"qwen-r1-aha-moment\",\n",
    "    learning_rate=5e-7,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    logging_steps=10,\n",
    "    max_steps=100,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=1,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    "    bf16=True,\n",
    "    # GRPO specific parameters\n",
    "    max_prompt_length=256,\n",
    "    max_completion_length=1024, # max length of the generated output for our solution\n",
    "    num_generations=2,\n",
    "    beta=0.001,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225c21d6-84e3-497c-91a8-a7d9c43c475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRPOTrainer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15b2ed9e-94e3-4327-8fbd-c5decd60a169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4eb91cc5-ecab-48db-98ce-48193b08a32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.optim.lr_scheduler.CosineAnnealingLR"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.optim.lr_scheduler.CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f187f919-853a-4abf-9723-5a8d26becc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = GRPOTrainer(\n",
    "    model=model_config.model_name_or_path,\n",
    "    reward_funcs=[format_reward_func, equation_reward_func],\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    #optimizers=(torch.optim.SGD,torch.optim.lr_scheduler.CosineAnnealingLR),\n",
    "    peft_config=get_peft_config(model_config),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c12844d-67cf-4f5c-ae4a-1f63e15d25ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0fbd39-3bf8-48f0-9d5a-8d623a147baa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c742b0d3-0752-4700-9922-86ee615b2896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjiaqi-zjq\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd080592ae814fb2922fadc5da344cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111906555551184, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mscer/workingspace/longcot_llm/wandb/run-20250209_144008-eb8mkmf7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jiaqi-zjq/huggingface/runs/eb8mkmf7' target=\"_blank\">qwen-r1-aha-moment</a></strong> to <a href='https://wandb.ai/jiaqi-zjq/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jiaqi-zjq/huggingface' target=\"_blank\">https://wandb.ai/jiaqi-zjq/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jiaqi-zjq/huggingface/runs/eb8mkmf7' target=\"_blank\">https://wandb.ai/jiaqi-zjq/huggingface/runs/eb8mkmf7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 24/100 1:04:22 < 3:42:22, 0.01 it/s, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "# Save model\n",
    "trainer.save_model(training_args.output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed5871e-2c57-4aab-a293-b949c40511f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1379be-d8d8-435e-9e2e-e890d79bcd52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
